# KMOOC 인공지능과 기계학습 : W3-1 회귀(regression)

## 1. 지도학습(Supervised Learning)

알고리즘으로 학습하고자하는 대상 함수. 타겟 함수가 있고. input X가 들어오면 Y로 매핑해주는 함수가 타겟 함수다. 알고리즘은 타겟 함수를 학습해야 함. y가 뭐냐에 따라서 분별 태스크, 회귀 태스크로 나뉘어진다.

- 분별: y가 이산 값을 가질 때. 사람의 이미지가 인풋으로 들어왔을 때 남자냐 여자냐.
- 회귀: Y가 continuous한 값일 때.

만약 함수 f가 정해져있다면 학습할 필요가 없다. 즉 함수 f는 모르는 것. 대신 이 함수 f를 나타내는 input, output 데이터값을 모아놨다. 여기서 함수 f를 추정하는 것.

D가 알고리즘의 인풋으로 들어온도록 가정. 해당 인풋이 x일 때 아웃풋이 y였다. 이런 쌍이 n개가 있다는 수식임. 이것을 지도학습이라고 한다. 인풋 x면 그에 해당하는 y값은 뭐야. 라고 딱 데이터셋으로 보여주기 때문에 지도학습이라고 한다.

알고자하는 f에 가장 가깝도록 g를 계속 수정해나간다. 근데 f를 모르는 상황에서 이 g가 f와 비슷한지 어떻게 아는가. 회귀 태스크와 성능 측정법ㅂ.

## 2. 회귀 태스크

타겟 함수 f를 학습하는 것. input -> independent, output -> dependent

f는 모른다. x -> y 쌍으로 이루어진 데이터셋 받을 것. 

이상적으로는 y = f(x) 이지만. 하지만 랜덤 노이즈 입실론에 의해 perturbation(변형)된 것이라고 가정한다. 이 입실론은 평균적으론 노이즈가 없지만(평균0) 정규분포 노이즈다.

학습 알고리즘(learner): 함수 f와 최대한 가까이 모사하는 g이기를. 세타 값을 어떻게 세팅하느냐에 따라서 모양이 달라진다.

첫, 두번째가 가정이다. 인풋 엑스가 들어왔을 때 y의 분포는 정규 분포가 되고. 민은 g 함수의 결과, 그리고 시그마 분산.

log likelihood. 우도를 최대화하는 세타를 찾아가는 과정임. 첫 번째 x일 때 y일 확률 로그 부분만 세타와 관계있고, 두 번째 p(xi) 부분은 세타와 관련 없다.




